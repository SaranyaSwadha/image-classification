#IMPORTING LIBRARIES
import numpy as np
import os
import pandas as pd
import random
from sklearn.metrics import confusion_matrix
from sklearn.utils import shuffle           
import seaborn as sn; sn.set(font_scale=1.4)
import matplotlib.pyplot as plt             
import cv2                                 
import tensorflow as tf 
from tqdm import tqdm
import gradio as gr
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers,models
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

#LOADING DATASET AND COUNTING THE IMAGES IN IT
from pathlib import Path
from PIL import Image
loaded_data = Path("C:\\Users\\saipr\\OneDrive\\Desktop\\DL\\archive")
total_image_count = 0
vehicle_categories = list(loaded_data.glob('*'))
if len(vehicle_categories) > 0:
    for vehicle_category in vehicle_categories:
        vehicle_images = list(vehicle_category.glob('*.jpeg')) + list(vehicle_category.glob('*.png')) + list(vehicle_category.glob('*.jpg'))
        if len(vehicle_images) > 0:
            total_image_count += len(vehicle_images)
    print(f"Total number of vehicle images found: {total_image_count}")
else:
    print("No vehicle categories (subfolders) found in the directory.")

#TRAINING AND TESTING

set_height, set_width = 150, 150
batch_size = 32

train_images = tf.keras.preprocessing.image_dataset_from_directory(
    loaded_data,
    subset="training",
    validation_split = 0.25,
    seed=123,
    image_size=(set_height, set_width),
    batch_size=batch_size
)
val_images = tf.keras.preprocessing.image_dataset_from_directory(
    loaded_data,
    subset="validation",  
    validation_split=0.25,  
    seed=123,
    image_size=(set_height, set_width),
    batch_size=batch_size
)
vehicle_classes = train_images.class_names
print(vehicle_classes)
dataset_classes = 3

#HYPER-PARAMETER TUNING
import matplotlib.pyplot as plt

def create_cnn_model(dropout_rate):
    model = Sequential([
        layers.experimental.preprocessing.Rescaling(1./255, input_shape=(set_height, set_width, 3)),
        layers.Conv2D(16, 3, padding='same', activation='relu'),
        layers.MaxPooling2D(),
        layers.Conv2D(32, 3, padding='same', activation='relu'),
        layers.MaxPooling2D(),
        layers.Conv2D(64, 3, padding='same', activation='relu'),
        layers.MaxPooling2D(),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(dropout_rate),  # Add dropout layer with the specified rate
        layers.Dense(dataset_classes, activation='softmax')
    ])

    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])

    return model

#Define a list of dropout rates to try
dropout_rates = [0.0, 0.2, 0.4]

# Store training history for each model
training_histories = []

# Train models with different dropout rates
for dropout_rate in dropout_rates:
    print(f"Training model with dropout rate: {dropout_rate}")
    model = create_cnn_model(dropout_rate)
    history = model.fit(
        train_images,
        validation_data=val_images,
        epochs=20
    )
    training_histories.append((dropout_rate,history))

#PLOTTING THE DROP-OUT RATES TO FIND THE GRAPH

plt.figure(figsize=(12, 8))
for dropout_rate, history in training_histories:
    plt.plot(history.history['val_accuracy'], label=f'Dropout Rate: {dropout_rate}')
plt.title('Validation Accuracy vs. Epochs for Different Dropout Rates')
plt.xlabel('Epochs')
plt.ylabel('Validation Accuracy')
plt.legend()
plt.grid(True)
plt.show()

#BUILDING MODEL
layers.experimental.preprocessing.Rescaling(1./255, input_shape=(set_height, set_width, 3))
model = Sequential([
    Conv2D(32, (3, 3),padding='same', activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3),padding='same', activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3),padding='same', activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(256, (3, 3),padding='same', activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(3, activation='softmax')  # Three classes
])

#COMPILING
model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
  train_images,
  validation_data=val_images,
  epochs=20
)

#SAVING THE MODEL
model.save('model.activity1')

#PREDICITION
predictions = model.predict(val_images)

def predict_input_image(img):
  img_4d=img.reshape(-1,150,150,3)
  prediction=model.predict(img_4d)[0]
  return {vehicle_classes[i]: float(prediction[i]) for i in range(3)}

#GRADIO-INTERFACE
image = gr.inputs.Image(shape=(150,150))

label = gr.outputs.Label(num_top_classes=3)

gr.Interface(fn=predict_input_image, inputs=image, outputs=label,interpretation='default').launch(debug='True',share=True)
